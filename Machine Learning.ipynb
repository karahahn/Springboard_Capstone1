{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global land temperature data by city, with latitude/longitude values\n",
    "filename = 'Global-Land-Temperatures-By-City.csv'\n",
    "temp_df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# US federal emergency data, join on county\n",
    "filename1 = 'federal_emergencies.csv'\n",
    "disaster_df = pd.read_csv(filename1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data of latitude/longitude and county to merge two dataframes\n",
    "filename2 = 'zip_codes_states.csv'\n",
    "us_join = pd.read_csv(filename2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df: drop all countries except US and drop NaN values\n",
    "temp_us = temp_df[temp_df['Country'] == 'United States'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df: create new lat/long columns dropping NESW direction\n",
    "temp_us['lat_n'] = [float(lat[:-1]) if lat[-1]=='N' else -1*float(lat[:-1]) for lat in temp_us.loc[:,'Latitude']]\n",
    "temp_us['lon_n'] = [float(lon[:-1]) if lon[-1]=='E' else -1*float(lon[:-1]) for lon in temp_us.loc[:,'Longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique coordinates in the temp_us dataframe\n",
    "temp_us_coords = temp_us[['lat_n','lon_n']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function adds a column with pythagorean theorem \n",
    "def coord2loc(coords):\n",
    "    us2 = us_join.copy()\n",
    "    us2['dist'] = ((us2.latitude-coords.lat_n)**2+(us2.longitude-coords.lon_n)**2)**(1/2)\n",
    "    state = us2.loc[us2.dist==min(us2.dist)]['state'].values[0]\n",
    "    county = us2.loc[us2.dist==min(us2.dist)]['county'].values[0]\n",
    "    return([coords.lat_n,coords.lon_n,state,county])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe to join on between\n",
    "join = pd.DataFrame([coord2loc(coords[1]) for coords in temp_us_coords.iterrows()])\n",
    "join.columns = ['lat_n','lon_n','state','county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge temp_df and us_join\n",
    "temp_county = pd.merge(temp_us, join, how='left', on = ['lat_n', 'lon_n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add \"County\" to the end of the county names to join on the disaster dataframe\n",
    "temp_county['countyname'] = temp_county.county +' County'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_county['dt'] = pd.to_datetime(temp_county['dt'], format='%Y/%m/%d')\n",
    "temp_county['year'] = temp_county['dt'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_county.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract month number for each row\n",
    "temp_county_seasons = temp_county.copy()\n",
    "temp_county_seasons['month'] = temp_county_seasons['dt'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign seasons to each date\n",
    "temp_county_seasons['month'] = temp_county_seasons['month'].astype(str).astype(int)\n",
    "season_map = {12: 'Winter', 1: 'Winter', 2: 'Winter', \n",
    "              3: 'Spring', 4: 'Spring', 5: 'Spring', \n",
    "              6: 'Summer', 7: 'Summer', 8: 'Summer', \n",
    "              9: 'Fall', 10: 'Fall', 11: 'Fall'}\n",
    "def mapper(month):\n",
    "    return season_map[month]\n",
    "temp_county_seasons['season'] = temp_county_seasons['month'].apply(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign United States common regions to the states\n",
    "## Midwest Region\n",
    "east_north_central_midwest_region = ['IL','IN','MI','OH','WI']\n",
    "d1 = dict.fromkeys(east_north_central_midwest_region, 'east north central midwest region')\n",
    "\n",
    "west_north_central_midwest_region = ['IA','KS','MO','MN','ND','SD','NE']\n",
    "d2 = dict.fromkeys(west_north_central_midwest_region, 'west north central midwest region')\n",
    "\n",
    "## Northeast Region\n",
    "new_england_northeast_region = ['CT','ME','MA','NH','RI','VT']\n",
    "d3 = dict.fromkeys(new_england_northeast_region, 'new england northeast region')\n",
    "\n",
    "midatlantic_northeast_region = ['NY','PA','NJ']\n",
    "d4 = dict.fromkeys(midatlantic_northeast_region, 'midatlantic northeast region')\n",
    "\n",
    "## West Region\n",
    "pacific_west_region = ['AK','OR','WA','CA','HI']\n",
    "d5 = dict.fromkeys(pacific_west_region, 'pacific west region')\n",
    "\n",
    "mountain_west_region = ['AZ','CO','NM','UT','NV','WY','ID','MT']\n",
    "d6 = dict.fromkeys(mountain_west_region, 'mountain west region')\n",
    "\n",
    "## South Region\n",
    "west_south_central_south_region = ['AR','LA','OK','TX']\n",
    "d7 = dict.fromkeys(west_south_central_south_region, 'west south central south region')\n",
    "\n",
    "east_south_central_south_region = ['AL','MS','TN','KY']\n",
    "d8 = dict.fromkeys(east_south_central_south_region, 'east south central south region')\n",
    "\n",
    "south_atlantic_south_region = ['WV','MD','DC','DE','VA','NC','SC','GA','FL']\n",
    "d9 = dict.fromkeys(south_atlantic_south_region, 'south atlantic south region')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_county_region = temp_county_seasons.copy()\n",
    "d = {**d1, **d2, **d3, **d4, **d5, **d6, **d7, **d8, **d9}\n",
    "temp_county_region['region'] = temp_county_region['state'].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_county_region['date_delta'] = (temp_county_region['dt'] - temp_county_region['dt'].min())  / np.timedelta64(1,'D')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join for RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_county_region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disaster data - create year column\n",
    "disasterdf = disaster_df.copy()\n",
    "disasterdf['Declaration Date'] = pd.to_datetime(disasterdf['Declaration Date'], format='%m/%d/%Y')\n",
    "disasterdf['Year'] = disasterdf['Declaration Date'].dt.year\n",
    "\n",
    "# create region column\n",
    "disasterdf['Region'] = disasterdf['State'].map(d)\n",
    "\n",
    "# select columns for merge \n",
    "disasterdf = disasterdf[['Declaration Type','Declaration Date','State','County','Disaster Type','Year','Region']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# disaster data - delete duplicate listing of disasters on the same day (ie. unique disaster per day per state)\n",
    "disasterdf = disasterdf.drop_duplicates(subset=['Declaration Date','Disaster Type','State','Year']).sort_values('Declaration Date')\n",
    "\n",
    "# select top 5 disasters\n",
    "disasterdf = disasterdf[disasterdf['Disaster Type'].isin(['Tornado','Flood','Fire','Hurricane','Storm'])]\n",
    "\n",
    "# create new disaster count column \n",
    "disasterdf['Disaster Count'] = disasterdf['Disaster Type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# disaster data groupby, get disaster count by region, disaster type, and year\n",
    "disasterdf = disasterdf.groupby(['Region','Disaster Type','Year'])[['Disaster Count']].count().unstack(fill_value=0).stack().reset_index()\n",
    "disasterdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of temperature data to organize for the join\n",
    "tempdf = temp_county_region.copy()\n",
    "tempdf = tempdf.sort_values('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select columns for join\n",
    "tempdf = tempdf[['year','AverageTemperature','season','region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# temperature data - feature engineer temperature by region and year\n",
    "tempdf = tempdf.groupby(['region','year']).agg({'AverageTemperature': ['mean','min','max','std']}).unstack(fill_value=0).stack().reset_index()\n",
    "tempdf.columns = [\"_\".join(x) for x in tempdf.columns.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns in temperature data frame\n",
    "tempdf = tempdf.rename(columns={\"region_\": \"region\", \"year_\": \"year\"});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for seasonal temperature by year and region\n",
    "season = temp_county_region.pivot_table('AverageTemperature', index=['year','region'], columns='season', fill_value='NaN').reset_index()\n",
    "season.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the temperature dataframe with the seasonal temperatures to obtain more features\n",
    "join_dataframe = pd.merge(tempdf, season, left_on=['region','year'], right_on=['region','year'], how='left')\n",
    "join_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disasterdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join temperature and disaster dataframe \n",
    "joindf = pd.merge(disasterdf, join_dataframe, left_on=['Region','Year'], right_on=['region','year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate columns\n",
    "joindf = joindf.drop(columns = ['region','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joindf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest for disaster/region pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disasters = joindf['Disaster Type'].unique()\n",
    "regions = joindf['Region'].unique()\n",
    "\n",
    "combined = [(s, f) for s in regions for f in disasters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joindf = joindf.set_index(['Region','Disaster Type']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joindf.loc[('east north central midwest region','Fire')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in combined:\n",
    "    try:\n",
    "        print(joindf.loc[k])\n",
    "    except:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randforest(key):\n",
    "    \n",
    "    # random forest regression\n",
    "    X = joindf.loc[key].drop(['Disaster Count'], axis=1).values\n",
    "    y = joindf.loc[key]['Disaster Count'].values\n",
    "    names = join_dataframe[['AverageTemperature_mean','AverageTemperature_min','AverageTemperature_max','AverageTemperature_std','Fall','Spring','Summer','Winter']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "    # Create the regressor: \n",
    "    rf = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "\n",
    "    # Fit the regressor to the training data\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data: y_pred\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    print('R^2 or Score:', rf.score(X_test, y_test))\n",
    "    print (\"Features sorted by their importance:\", sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in combined:\n",
    "    try:\n",
    "        print(k, randforest(k))\n",
    "    except:\n",
    "        print(k, 'does not exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four region/disaster pairing with the highest score are:\n",
    "   \n",
    "   east nort central midwest region, storm\n",
    "    \n",
    "   mountain west region, fire\n",
    "   \n",
    "   mountain west region, storm\n",
    "   \n",
    "   pacific west region, fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temperature prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use those 4 region/disaster pairings to focus on for predicting average temperature and disaster counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = joindf.columns.drop('Disaster Count')\n",
    "\n",
    "# linear regression to obtain independent variable predictions to use for random forest\n",
    "def linearreg(key, column, year):\n",
    "    X = joindf.loc[key][['Year']].values\n",
    "    y = joindf.loc[key][column].values\n",
    "\n",
    "    X = X.reshape(-1,1)\n",
    "    y = y.reshape(-1,1)\n",
    "\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    print(model.predict(year))\n",
    "    #plt.scatter(X, y,color='r')\n",
    "\n",
    "    #plt.plot(X, model.predict(X),color='k')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randforestpredictor(x_var, key):\n",
    "    \n",
    "    # random forest regression\n",
    "    X = joindf.loc[key].drop(['Disaster Count'], axis=1).values\n",
    "    y = joindf.loc[key]['Disaster Count'].values\n",
    "    names = join_dataframe[['AverageTemperature_mean','AverageTemperature_min','AverageTemperature_max','AverageTemperature_std','Fall','Spring','Summer','Winter']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "    # Create the regressor: \n",
    "    rf = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "\n",
    "    # Fit the regressor to the training data\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data: y_pred\n",
    "    y_var = rf.predict(x_var)\n",
    "    \n",
    "    print(y_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### east north central midwest region / storm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict year 2070\n",
    "for col in columns:\n",
    "    print(linearreg(('east north central midwest region', 'Storm'), col, 2070))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf model prediction using these values \n",
    "# year 2070\n",
    "x_2070 = [[2070, 11.8441235, -6.04739043, 26.66335563, 9.35311371, 13.31567534, 11.38216591, 23.25243497, -0.56003033]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest using temperature values to predict disaster counts\n",
    "randforestpredictor(x_2070, ('east north central midwest region', 'Storm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict year 2120\n",
    "for col in columns:\n",
    "    print(linearreg(('east north central midwest region', 'Storm'), col, 2120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf model prediction using these values \n",
    "x_2120 = [[2120, 12.80583185, -4.78466965, 27.34652591, 9.15965208, 14.18573028, 12.53277554, 24.01557468, 0.51006306]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest using temperature values to predict disaster counts\n",
    "randforestpredictor(x_2120, ('east north central midwest region', 'Storm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict year 2220\n",
    "for col in columns:\n",
    "    print(linearreg(('east north central midwest region', 'Storm'), col, 2220))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf model prediction using these values \n",
    "x_2220 = [[2220, 14.72924853, -2.25922808, 28.71286647, 8.77272884, 15.92584018, 14.8339948, 25.54185409, 2.65024985]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest using temperature values to predict disaster counts\n",
    "randforestpredictor(x_2220, ('east north central midwest region', 'Storm'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mountain west region / fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict year 2070\n",
    "for col in columns:\n",
    "    print(linearreg(('mountain west region', 'Fire'), col, 2070))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf model prediction using these values \n",
    "# year 2070\n",
    "x_2070 = [[2070, 16.1550363, -6.30327229, 33.96463585, 10.28919724, 17.18435082, 15.6861039, 26.97222201, 4.73691442]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest using temperature values to predict disaster counts\n",
    "randforestpredictor(x_2070, ('mountain west region', 'Fire'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict year 2120\n",
    "for col in columns:\n",
    "    print(linearreg(('mountain west region', 'Fire'), col, 2120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf model prediction using these values \n",
    "x_2120 = [[2120, 17.03366165, -5.15347589, 34.68687805, 10.4455514, 18.29039419, 16.95982956, 27.84635199, 4.97668426]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest using temperature values to predict disaster counts\n",
    "randforestpredictor(x_2120, ('mountain west region', 'Fire'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict year 2220\n",
    "for col in columns:\n",
    "    print(linearreg(('mountain west region', 'Fire'), col, 2220))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf model prediction using these values \n",
    "x_2220 = [[2220, 18.79091235, -2.85388308, 36.13136245, 10.75825971, 20.50248093, 19.50728087, 29.59461194, 5.45622396]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest using temperature values to predict disaster counts\n",
    "randforestpredictor(x_2220, ('mountain west region', 'Fire'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mountain west region / storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict year 2070\n",
    "for col in columns:\n",
    "    print(linearreg(('mountain west region', 'Storm'), col, 2070))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf model prediction using these values \n",
    "# year 2070\n",
    "x_2070 = [[2070, 16.1550363, -6.30327229, 33.96463585, 10.28919724, 17.18435082, 15.6861039, 26.97222201, 4.73691442]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest using temperature values to predict disaster counts\n",
    "randforestpredictor(x_2070, ('mountain west region', 'Storm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict year 2120\n",
    "for col in columns:\n",
    "    print(linearreg(('mountain west region', 'Storm'), col, 2120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf model prediction using these values \n",
    "x_2120 = [[2120, 17.03366165, -5.15347589, 34.68687805, 10.4455514, 18.29039419, 16.95982956, 27.84635199, 4.97668426]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest using temperature values to predict disaster counts\n",
    "randforestpredictor(x_2120, ('mountain west region', 'Storm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict year 2220\n",
    "for col in columns:\n",
    "    print(linearreg(('mountain west region', 'Storm'), col, 2220))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf model prediction using these values \n",
    "x_2220 = [[2220, 18.79091235, -2.85388308, 36.13136245, 10.75825971, 20.50248093, 19.50728087, 29.59461194, 5.45622396]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest using temperature values to predict disaster counts\n",
    "randforestpredictor(x_2220, ('mountain west region', 'Storm'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pacific west region / fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict year 2070\n",
    "for col in columns:\n",
    "    print(linearreg(('pacific west region', 'Fire'), col, 2070))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf model prediction using these values \n",
    "# year 2070\n",
    "x_2070 = [[2070, 16.22593332, -11.75978244, 30.15020206, 6.23724319, 17.80460639, 15.37083785, 22.22981778, 9.61202119]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest using temperature values to predict disaster counts\n",
    "randforestpredictor(x_2070, ('pacific west region', 'Fire'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict year 2120\n",
    "for col in columns:\n",
    "    print(linearreg(('pacific west region', 'Fire'), col, 2120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf model prediction using these values \n",
    "x_2120 = [[2120, 17.05502805, -8.660967, 31.02268488, 6.322795, 18.80943167, 16.51741249, 23.06318462, 10.00196381]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest using temperature values to predict disaster counts\n",
    "randforestpredictor(x_2120, ('pacific west region', 'Fire'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict year 2220\n",
    "for col in columns:\n",
    "    print(linearreg(('pacific west region', 'Fire'), col, 2220))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf model prediction using these values \n",
    "x_2220 = [[2220, 18.71321751, -2.46333612, 32.7676505, 6.49389862, 20.81908223, 18.81056178, 24.7299183, 10.78184903]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest using temperature values to predict disaster counts\n",
    "randforestpredictor(x_2220, ('pacific west region', 'Fire'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
